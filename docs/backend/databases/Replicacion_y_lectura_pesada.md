# Modulo 34. ReplicaciÃ³n y lectura pesada

## ğŸ§­ 34.1. Por quÃ© replicar una base de datos

Cuando una base de datos crece:

- Las lecturas se multiplican (dashboards, APIs, informes, consultas de usuariosâ€¦),
- Pero **no todas esas lecturas tienen que ir al mismo servidor**.

ğŸ‘‰ Al replicar la base:

- Mantienes **un nodo primario** para escrituras,
- Y **uno o varios nodos secundarios** que reciben copias de los datos para lecturas.

ğŸ“Œ Ventajas prÃ¡cticas:

- ğŸš€ Escalas lecturas sin saturar el nodo principal.
- ğŸ§¯ Tienes redundancia en caso de fallo del primario.
- ğŸ“Š Puedes usar los secundarios para reporting, backups o tareas pesadas sin afectar la producciÃ³n.

## ğŸ§  34.2. Arquitectura bÃ¡sica primario/secundario

```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ AplicaciÃ³nâ”‚
        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
             â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Servidor Primario (write) â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Nodo Secundario 1 â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚ Nodo Secundario 2 â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

- El **primario** acepta INSERT, UPDATE y DELETE.
- Los **secundarios** replican esos cambios automÃ¡ticamente.
- La aplicaciÃ³n puede **dirigir las lecturas** a los secundarios.

ğŸ‘‰ Este patrÃ³n se llama *asynchronous replication* (replicaciÃ³n asÃ­ncrona) cuando los secundarios no bloquean las escrituras del primario.

## ğŸ§­ 34.3. Ejemplo sencillo â€” PostgreSQL streaming replication

SupÃ³n que tienes dos servidores:

- `db1` (primario)
- `db2` (secundario)

En `db1`:

```
# postgresql.conf
wal_level = replica
max_wal_senders = 5

```

En `db2`:

```
primary_conninfo = 'host=db1 user=replicador password=xxxx'

```

Luego inicializas la rÃ©plica:

```bash
pg_basebackup -h db1 -D /var/lib/postgresql/data -U replicador -P --wal-method=stream

```

ğŸ‘‰ A partir de ahÃ­, `db2` recibirÃ¡ en tiempo real los cambios de `db1`.

ğŸ“Œ No necesitas que la aplicaciÃ³n cambie nada en la lÃ³gica de escritura.

Solo decides a quÃ© nodo va cada consulta de lectura.

## ğŸ§  34.4. Lecturas escaladas â€” distribuir carga

Un patrÃ³n comÃºn:

- Todas las **escrituras** (INSERT/UPDATE/DELETE) â†’ van al **primario**.
- Las **lecturas pesadas o repetitivas** â†’ se envÃ­an a **uno o varios secundarios**.

Ejemplo con un balanceador simple:

```jsx
function getReadConnection() {
  // Balanceo simple round-robin entre rÃ©plicas
  const replicas = [dbReplica1, dbReplica2];
  return replicas[Math.floor(Math.random() * replicas.length)];
}

function getWriteConnection() {
  return dbPrimary;
}

```

ğŸ‘‰ AsÃ­ reduces la presiÃ³n sobre el primario, evitando cuellos de botella.

ğŸ“Œ Muy usado en aplicaciones con muchas lecturas (ecommerce, SaaS, APIs pÃºblicasâ€¦).

## ğŸ§­ 34.5. Consistencia eventual â€” concepto clave

La replicaciÃ³n **no es instantÃ¡nea**.

Existe un pequeÃ±o retraso entre:

- Escribir en el primario,
- Y ver ese cambio reflejado en un secundario.

Ejemplo:

1. INSERT en primario a las 12:00:00
2. SELECT en secundario a las 12:00:00.010 â†’ todavÃ­a no aparece.
3. SELECT en secundario a las 12:00:00.050 â†’ ahora sÃ­ aparece.

ğŸ“Œ Este retraso (replication lag) puede ser:

- Imperceptible (milisegundos), o
- Notable (segundos o minutos) si el sistema estÃ¡ bajo carga.

ğŸ‘‰ Esto se llama **consistencia eventual**:

Los datos **terminan siendo consistentes**, pero no **instantÃ¡neamente consistentes**.

## ğŸ§  34.6. Ejemplo real de inconsistencia temporal

Imagina que un usuario crea un pedido:

```jsx
await dbPrimary.query('INSERT INTO pedidos ...');

```

Y justo despuÃ©s la app lo consulta para mostrarlo en su panel:

```jsx
const result = await dbReplica.query('SELECT * FROM pedidos WHERE id = ...');

```

Si la consulta de lectura va a una rÃ©plica que **aÃºn no recibiÃ³ la actualizaciÃ³n**,

ğŸ‘‰ la app mostrarÃ¡ â€œno hay pedidosâ€.

ğŸ“Œ Este es un **problema comÃºn** en sistemas con rÃ©plicas.

### Soluciones tÃ­picas:

- Para operaciones sensibles: **leer del primario** inmediatamente despuÃ©s de escribir.
- O usar mecanismos de sincronizaciÃ³n (por ejemplo, esperar confirmaciÃ³n de replicaciÃ³n en algunos motores).

## ğŸ§­ 34.7. ReplicaciÃ³n sÃ­ncrona vs asÃ­ncrona

| Tipo | CaracterÃ­sticas | Ventajas | Desventajas |
| --- | --- | --- | --- |
| **AsÃ­ncrona** (la mÃ¡s comÃºn) | El primario no espera a los secundarios | RÃ¡pida, escalable, sin bloquear escrituras | PequeÃ±o retraso entre nodos |
| **SÃ­ncrona** | El primario espera confirmaciÃ³n de al menos un secundario | Cero lag (consistencia fuerte) | Menor rendimiento, mÃ¡s latencia en escritura |

ğŸ‘‰ En la prÃ¡ctica:

- AsÃ­ncrona se usa para escalabilidad de lecturas.
- SÃ­ncrona se usa cuando no se puede perder ni un solo dato.

Ejemplo:

- Plataforma de streaming â†’ asÃ­ncrona.
- Sistema bancario â†’ sÃ­ncrona.

## ğŸ§  34.8. Failover y alta disponibilidad

Otro beneficio de la replicaciÃ³n:

ğŸ‘‰ Si el nodo primario falla, **uno de los secundarios puede asumir su rol**.

- **Failover manual** â†’ un administrador promueve un nodo secundario.
- **Failover automÃ¡tico** â†’ herramientas como Patroni, Stolon, Orchestrator o RDS lo hacen de forma controlada.

Ejemplo en PostgreSQL:

```bash
pg_ctl promote

```

ğŸ‘‰ El nodo replica pasa a ser primario.

ğŸ“Œ Esto mejora la disponibilidad sin requerir copias manuales de Ãºltima hora.

## ğŸ§­ 34.9. ReplicaciÃ³n + particionamiento = escalabilidad real

- El particionamiento (MÃ³dulo 33) divide grandes tablas en pedazos manejables dentro de un nodo.
- La replicaciÃ³n (MÃ³dulo 34) permite **multiplicar nodos para distribuir carga**.

ğŸ‘‰ Combinarlos da lugar a arquitecturas muy potentes:

- Primario particionado, con mÃºltiples rÃ©plicas por shard.
- Lecturas distribuidas geogrÃ¡ficamente.
- Alta disponibilidad con failover automatizado.

ğŸ“Œ Ejemplo real: muchas plataformas globales (Netflix, GitHub, Shopify) usan este patrÃ³n hÃ­brido.

## ğŸ§  34.10. Buenas prÃ¡cticas en entornos con replicaciÃ³n

- Define quÃ© consultas pueden ir a rÃ©plicas (solo lecturas no crÃ­ticas).
- Mide y monitorea el **replication lag** constantemente.
- Para operaciones sensibles, **forzar lectura al primario**.
- Automatiza failover para evitar downtime prolongado.
- Documenta cÃ³mo se maneja cada escenario (falla del primario, recuperaciÃ³n, etc.).
- No uses rÃ©plicas solo como â€œbackupâ€: su propÃ³sito es **distribuir carga** y **mejorar disponibilidad**.

## ğŸš¨ 34.11. Errores comunes

- Leer datos reciÃ©n escritos desde una rÃ©plica â†’ inconsistencias visibles.
- Asumir que la replicaciÃ³n es instantÃ¡nea.
- No monitorear el lag â†’ consultas lentas y datos desfasados.
- No probar el failover â†’ caos cuando el primario se cae.
- Pensar que tener rÃ©plicas reemplaza a los backups (âš ï¸ no lo hace).